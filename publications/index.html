<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Marzieh Fadaee | publications</title>
  <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

  <link rel="shortcut icon" href="https://marziehf.github.io//assets/img/favicon.ico">

  <link rel="stylesheet" href="https://marziehf.github.io//assets/css/main.css">
  <link rel="canonical" href="https://marziehf.github.io//publications/">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    
    <span class="site-title">
        
        <strong>Marzieh</strong> Fadaee
    </span>
    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="https://marziehf.github.io//">about</a>

        <!-- Blog -->
        <a class="page-link" href="https://staff.fnwi.uva.nl/m.fadaee/files/CV.pdf">vitae</a>

        <!-- Pages -->
        
          
        
          
        
          
        
          
            <a class="page-link" href="https://marziehf.github.io//projects/">projects</a>
          
        
          
            <a class="page-link" href="https://marziehf.github.io//publications/">publications</a>
          
        
          
            <a class="page-link" href="https://marziehf.github.io//teaching/">teaching</a>
          
        
          
        
          
        

        <!-- CV link -->
        <!-- <a class="page-link" href="https://marziehf.github.io//assets/pdf/CV.pdf">vitae</a> -->

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <h5 class="post-description"></h5>
  </header>

  <article class="post-content publications clearfix">
    
<h3 class="year">2018</h3>
<ol class="bibliography"><li>

<div id="D18-1040">
  
    <span class="title">Back-Translation Sampling by Targeting Difficult Words in Neural Machine Translation</span>
    <span class="author">
      
        
          
            <em><b>Fadaee, Marzieh</b></em>,
          
        
      
        
          and
          
            
              <a href="https://staff.science.uva.nl/c.monz/" target="_blank">Monz, Christof</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>
    
    
      2018
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abstract</a>]
  
  
  
  
    [<a href="http://aclweb.org/anthology/D18-1040" target="_blank">PDF</a>]
  
  
    [<a href="https://aclanthology.coli.uni-saarland.de/papers/D18-1040/d18-1040.bib" target="_blank">bibtex</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Neural Machine Translation has achieved state-of-the-art performance for several language pairs using a combination of parallel and synthetic data. Synthetic data is often generated by back-translating sentences randomly sampled from monolingual data using a reverse translation model. While back-translation has been shown to be very effective in many cases, it is not entirely clear why. In this work, we explore different aspects of back-translation, and show that words with high prediction loss during training benefit most from the addition of synthetic data. We introduce several variations of sampling strategies targeting difficult-to-predict words using prediction losses and frequencies of words. In addition, we also target the contexts of difficult words and sample sentences that are similar in context. Experimental results for the WMT news translation task show that our method improves translation quality by up to 1.7 and 1.2 Bleu points over back-translation using random sampling for German-English and English-German, respectively</p>
  </span>
  
</div>
</li>
<li>

<div id="2018arXiv180204681F">
  
    <span class="title">Examining the Tip of the Iceberg: A Data Set for Idiom Translation</span>
    <span class="author">
      
        
          
            <em><b>Fadaee, Marzieh</b></em>,
          
        
      
        
          
            
              <a href="http://liacs.leidenuniv.nl/~bisazzaa/" target="_blank">Bisazza, Arianna</a>,
            
          
        
      
        
          and
          
            
              <a href="https://staff.science.uva.nl/c.monz/" target="_blank">Monz, Christof</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC)</em>
    
    
      2018
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abstract</a>]
  
  
  
  
    [<a href="https://arxiv.org/abs/1802.04681" target="_blank">PDF</a>]
  
  
    [<a href="http://adsabs.harvard.edu/abs/2018arXiv180204681F" target="_blank">bibtex</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Neural Machine Translation (NMT) has been widely used in recent years with significant improvements for many language pairs. Although state-of-the-art NMT systems are generating progressively better translations, idiom translation remains one of the open challenges in this field. Idioms, a category of multiword expressions, are an interesting language phenomenon where the overall meaning of the expression cannot be composed from the meanings of its parts. A first important challenge is the lack of dedicated data sets for learning and evaluating idiom translation. In this paper we address this problem by creating the first large-scale data set for idiom translation. Our data set is automatically extracted from a widely used German-English translation corpus and includes, for each language direction, a targeted evaluation set where all sentences contain idioms and a regular training corpus where sentences including idioms are marked. We release this data set and use it to perform preliminary NMT experiments as the first step towards better idiom translation.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2017</h3>
<ol class="bibliography"><li>

<div id="fadaee-bisazza-monz:2017:Short2">
  
    <span class="title">Data Augmentation for Low-Resource Neural Machine Translation</span>
    <span class="author">
      
        
          
            <em><b>Fadaee, Marzieh</b></em>,
          
        
      
        
          
            
              <a href="http://liacs.leidenuniv.nl/~bisazzaa/" target="_blank">Bisazza, Arianna</a>,
            
          
        
      
        
          and
          
            
              <a href="https://staff.science.uva.nl/c.monz/" target="_blank">Monz, Christof</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL)</em>
    
    
      2017
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abstract</a>]
  
  
  
  
    [<a href="http://aclweb.org/anthology/P17-2090" target="_blank">PDF</a>]
  
  
    [<a href="https://aclanthology.coli.uni-saarland.de/papers/P17-2090/p17-2090.bib" target="_blank">bibtex</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The quality of a Neural Machine Translation system depends substantially on the
	availability of sizable parallel corpora.
	For low-resource language pairs this is not the case, resulting in poor
	translation quality. 
	Inspired by work in computer vision, we propose a novel data augmentation
	approach that targets low-frequency words by generating new sentence pairs
	containing rare words in new, synthetically created contexts.
	Experimental results on simulated low-resource settings show that our method
	improves translation quality by up to 2.9 BLEU points over the baseline and up
	to 3.2 BLEU over back-translation.</p>
  </span>
  
</div>
</li>
<li>

<div id="fadaee-bisazza-monz:2017:Short1">
  
    <span class="title">Learning Topic-Sensitive Word Representations</span>
    <span class="author">
      
        
          
            <em><b>Fadaee, Marzieh</b></em>,
          
        
      
        
          
            
              <a href="http://liacs.leidenuniv.nl/~bisazzaa/" target="_blank">Bisazza, Arianna</a>,
            
          
        
      
        
          and
          
            
              <a href="https://staff.science.uva.nl/c.monz/" target="_blank">Monz, Christof</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL)</em>
    
    
      2017
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abstract</a>]
  
  
  
  
    [<a href="http://aclweb.org/anthology/P17-2070" target="_blank">PDF</a>]
  
  
    [<a href="https://aclanthology.coli.uni-saarland.de/papers/P17-2070/p17-2070.bib" target="_blank">bibtex</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Distributed word representations are widely used for modeling words in NLP
	tasks. Most of the existing models generate one representation per word and do
	not consider different meanings of a word.   
	We present two approaches to learn multiple topic-sensitive representations per
	word by using Hierarchical Dirichlet Process. We observe that by modeling
	topics and integrating topic distributions for each document  we obtain
	representations that are able to distinguish between different meanings of a
	given word.
	Our models yield statistically significant improvements for the lexical
	substitution task 
	indicating that commonly used single word representations, even when combined
	with contextual information, are insufficient for this task.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2013</h3>
<ol class="bibliography"><li>

<div id="fadaee2013automatic">
  
    <span class="title">Automatic WordNet Construction Using Markov Chain Monte Carlo</span>
    <span class="author">
      
        
          
            <em><b>Fadaee, Marzieh</b></em>,
          
        
      
        
          
            
              <a href="https://staff.fnwi.uva.nl/h.ghader/" target="_blank">Ghader, Hamidreza</a>,
            
          
        
      
        
          
            
              <a href="http://ece.ut.ac.ir/en/~hfaili" target="_blank">Faili, Heshaam</a>,
            
          
        
      
        
          and
          
            
              <a href="http://ece.ut.ac.ir/en/~shakery" target="_blank">Shakery, Azadeh</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Polibits</em>
    
    
      2013
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abstract</a>]
  
  
  
  
    [<a href="https://staff.fnwi.uva.nl/m.fadaee/files/pwn.pdf" target="_blank">PDF</a>]
  
  
    [<a href="https://staff.fnwi.uva.nl/m.fadaee/files/pwn.bib" target="_blank">bibtex</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>WordNet is used extensively as a major lexical
resource in information retrieval tasks. However, the qualities
of existing Persian WordNets are far from perfect. They are
either constructed manually which limits the coverage of Persian
words, or automatically which results in unsatisfactory precision.
This paper presents a fully-automated approach for constructing
a Persian WordNet: A Bayesian Model with Markov chain
Monte Carlo (MCMC) estimation. We model the problem of
constructing a Persian WordNet by estimating the probability of
assigning senses (synsets) to Persian words. By applying MCMC
techniques in estimating these probabilities, we integrate prior
knowledge in the estimation and use the expected value of
generated samples to give the final estimates. This ensures great
performance improvement comparing with Maximum-Likelihood
and Expectation-Maximization methods. Our acquired WordNet
has a precision of 90.46&#37; which is a considerable improvement
in comparison with automatically-built WordNets in Persian.</p>
  </span>
  
</div>
</li></ol>


  </article>

  

  

</div>

      </div>
    </div>

    <footer>

  <div class="wrapper">
    &copy; Copyright 2019 Marzieh Fadaee.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme.

    
  </div>

</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="https://marziehf.github.io//assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
<script src="https://marziehf.github.io//assets/js/katex.js"></script>




<!-- Include custom icon fonts -->
<link rel="stylesheet" href="https://marziehf.github.io//assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="https://marziehf.github.io//assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-XXXXXXXXX', 'auto');
ga('send', 'pageview');
</script>


  </body>

</html>
